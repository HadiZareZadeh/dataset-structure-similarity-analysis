{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sample Similarity Analysis\n",
        "\n",
        "## Overview\n",
        "\n",
        "This notebook analyzes relationships between samples in the UCI Adult Income dataset. We'll compute similarity metrics (Euclidean distance, cosine similarity) and investigate how samples relate to each other.\n",
        "\n",
        "## Research Questions\n",
        "\n",
        "1. How similar are samples to each other?\n",
        "2. How many samples are closely related to a given sample?\n",
        "3. What patterns emerge in sample relationships?\n",
        "\n",
        "## Methodology\n",
        "\n",
        "- Compute pairwise similarity using multiple metrics\n",
        "- Analyze sample density and clustering\n",
        "- Identify outliers and closely related sample groups\n",
        "- Visualize relationships with heatmaps and distributions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics.pairwise import euclidean_distances, cosine_similarity\n",
        "from scipy.spatial.distance import pdist, squareform\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load and Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load UCI Adult Income dataset\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
        "columns = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status',\n",
        "           'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss',\n",
        "           'hours-per-week', 'native-country', 'income']\n",
        "\n",
        "try:\n",
        "    df = pd.read_csv(url, names=columns, na_values=' ?', skipinitialspace=True)\n",
        "except Exception as e:\n",
        "    # If URL fails, try alternative source\n",
        "    print(f\"Failed to load from primary URL: {e}\")\n",
        "    print(\"Trying alternative source...\")\n",
        "    try:\n",
        "        # Alternative: use sklearn's fetch_openml if available\n",
        "        from sklearn.datasets import fetch_openml\n",
        "        adult = fetch_openml(name='adult', version=2, as_frame=True, parser='pandas')\n",
        "        df = adult.frame\n",
        "        # Rename columns to match expected format\n",
        "        df.columns = columns\n",
        "        print(\"Successfully loaded UCI Adult Income dataset from OpenML\")\n",
        "    except Exception as e2:\n",
        "        raise RuntimeError(\n",
        "            f\"Failed to load dataset from both sources. \"\n",
        "            f\"Primary error: {e}, Secondary error: {e2}. \"\n",
        "            f\"Please ensure internet connection is available or download the dataset manually.\"\n",
        "        )\n",
        "\n",
        "# Remove rows with missing values\n",
        "df = df.dropna()\n",
        "\n",
        "print(f\"\\nDataset shape: {df.shape}\")\n",
        "print(f\"Columns: {df.columns.tolist()}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "print(df.head())\n",
        "print(f\"\\nDataset loaded successfully. No synthetic data is used in this project.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preprocess for Similarity Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Encode categorical variables\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns\n",
        "df_encoded = df.copy()\n",
        "\n",
        "label_encoders = {}\n",
        "for col in categorical_cols:\n",
        "    if col != 'income':  # Keep target separate\n",
        "        le = LabelEncoder()\n",
        "        df_encoded[col] = le.fit_transform(df[col].astype(str))\n",
        "        label_encoders[col] = le\n",
        "\n",
        "# Encode target\n",
        "target_encoder = LabelEncoder()\n",
        "y = target_encoder.fit_transform(df['income'])\n",
        "\n",
        "# Select features (exclude target)\n",
        "feature_cols = [col for col in df_encoded.columns if col != 'income']\n",
        "X = df_encoded[feature_cols].values\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "print(f\"Feature matrix shape: {X_scaled.shape}\")\n",
        "print(f\"Target distribution: {np.bincount(y)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compute Similarity Matrices\n",
        "\n",
        "We'll compute both Euclidean distance and cosine similarity. For large datasets, we'll use a sample."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sample subset for computational efficiency (use full dataset if small enough)\n",
        "n_samples_analysis = min(1000, len(X_scaled))\n",
        "sample_indices = np.random.choice(len(X_scaled), n_samples_analysis, replace=False)\n",
        "X_sample = X_scaled[sample_indices]\n",
        "y_sample = y[sample_indices]\n",
        "\n",
        "print(f\"Computing similarity for {n_samples_analysis} samples...\")\n",
        "\n",
        "# Euclidean distance\n",
        "euclidean_dist = euclidean_distances(X_sample)\n",
        "print(f\"Euclidean distance matrix shape: {euclidean_dist.shape}\")\n",
        "\n",
        "# Cosine similarity\n",
        "cosine_sim = cosine_similarity(X_sample)\n",
        "print(f\"Cosine similarity matrix shape: {cosine_sim.shape}\")\n",
        "\n",
        "# Convert cosine similarity to distance (1 - similarity)\n",
        "cosine_dist = 1 - cosine_sim\n",
        "\n",
        "print(\"\\nSimilarity matrices computed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analyze Sample Relationships"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# For each sample, count how many are within threshold\n",
        "threshold_euclidean = np.percentile(euclidean_dist[euclidean_dist > 0], 10)  # 10th percentile\n",
        "threshold_cosine = np.percentile(cosine_dist[cosine_dist > 0], 10)\n",
        "\n",
        "related_counts_euclidean = []\n",
        "related_counts_cosine = []\n",
        "\n",
        "for i in range(n_samples_analysis):\n",
        "    # Count samples within threshold (excluding self)\n",
        "    related_euclidean = np.sum((euclidean_dist[i] < threshold_euclidean) & (euclidean_dist[i] > 0))\n",
        "    related_cosine = np.sum((cosine_dist[i] < threshold_cosine) & (cosine_dist[i] > 0))\n",
        "    \n",
        "    related_counts_euclidean.append(related_euclidean)\n",
        "    related_counts_cosine.append(related_cosine)\n",
        "\n",
        "related_counts_euclidean = np.array(related_counts_euclidean)\n",
        "related_counts_cosine = np.array(related_counts_cosine)\n",
        "\n",
        "print(f\"Threshold (Euclidean): {threshold_euclidean:.4f}\")\n",
        "print(f\"Threshold (Cosine): {threshold_cosine:.4f}\")\n",
        "print(f\"\\nAverage related samples (Euclidean): {related_counts_euclidean.mean():.2f}\")\n",
        "print(f\"Average related samples (Cosine): {related_counts_cosine.mean():.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save results using pickle\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "results_dir = os.path.join(os.path.dirname(os.getcwd()), 'results')\n",
        "os.makedirs(results_dir, exist_ok=True)\n",
        "\n",
        "similarity_results = {\n",
        "    'euclidean_distances': euclidean_dist,\n",
        "    'cosine_distances': cosine_dist,\n",
        "    'related_counts_euclidean': related_counts_euclidean.tolist(),\n",
        "    'related_counts_cosine': related_counts_cosine.tolist(),\n",
        "    'threshold_euclidean': threshold_euclidean,\n",
        "    'threshold_cosine': threshold_cosine,\n",
        "    'n_samples_analyzed': n_samples_analysis\n",
        "}\n",
        "\n",
        "with open(os.path.join(results_dir, '01_similarity_results.pkl'), 'wb') as f:\n",
        "    pickle.dump(similarity_results, f)\n",
        "\n",
        "print(f\"\\nResults saved to: {os.path.join(results_dir, '01_similarity_results.pkl')}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(16, 10))\n",
        "\n",
        "# Distance distribution\n",
        "plt.subplot(2, 3, 1)\n",
        "euclidean_flat = euclidean_dist[euclidean_dist > 0].flatten()\n",
        "plt.hist(euclidean_flat, bins=50, alpha=0.7, edgecolor='black')\n",
        "plt.axvline(threshold_euclidean, color='r', linestyle='--', label='Threshold')\n",
        "plt.xlabel('Euclidean Distance', fontsize=12)\n",
        "plt.ylabel('Frequency', fontsize=12)\n",
        "plt.title('Euclidean Distance Distribution', fontsize=14, fontweight='bold')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Cosine distance distribution\n",
        "plt.subplot(2, 3, 2)\n",
        "cosine_flat = cosine_dist[cosine_dist > 0].flatten()\n",
        "plt.hist(cosine_flat, bins=50, alpha=0.7, edgecolor='black')\n",
        "plt.axvline(threshold_cosine, color='r', linestyle='--', label='Threshold')\n",
        "plt.xlabel('Cosine Distance', fontsize=12)\n",
        "plt.ylabel('Frequency', fontsize=12)\n",
        "plt.title('Cosine Distance Distribution', fontsize=14, fontweight='bold')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Related samples count (Euclidean)\n",
        "plt.subplot(2, 3, 3)\n",
        "plt.hist(related_counts_euclidean, bins=30, alpha=0.7, edgecolor='black')\n",
        "plt.xlabel('Number of Related Samples', fontsize=12)\n",
        "plt.ylabel('Frequency', fontsize=12)\n",
        "plt.title('Related Samples Count (Euclidean)', fontsize=14, fontweight='bold')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Related samples count (Cosine)\n",
        "plt.subplot(2, 3, 4)\n",
        "plt.hist(related_counts_cosine, bins=30, alpha=0.7, edgecolor='black')\n",
        "plt.xlabel('Number of Related Samples', fontsize=12)\n",
        "plt.ylabel('Frequency', fontsize=12)\n",
        "plt.title('Related Samples Count (Cosine)', fontsize=14, fontweight='bold')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Similarity heatmap (small subset)\n",
        "plt.subplot(2, 3, 5)\n",
        "heatmap_size = min(100, n_samples_analysis)\n",
        "heatmap_indices = np.random.choice(n_samples_analysis, heatmap_size, replace=False)\n",
        "sns.heatmap(euclidean_dist[np.ix_(heatmap_indices, heatmap_indices)], \n",
        "            cmap='viridis_r', cbar_kws={'label': 'Distance'}, square=True)\n",
        "plt.title(f'Euclidean Distance Heatmap (sample of {heatmap_size})', fontsize=14, fontweight='bold')\n",
        "\n",
        "# Correlation between metrics\n",
        "plt.subplot(2, 3, 6)\n",
        "plt.scatter(related_counts_euclidean, related_counts_cosine, alpha=0.5)\n",
        "plt.xlabel('Related Samples (Euclidean)', fontsize=12)\n",
        "plt.ylabel('Related Samples (Cosine)', fontsize=12)\n",
        "plt.title('Correlation Between Similarity Metrics', fontsize=14, fontweight='bold')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Summary statistics\n",
        "print(\"\\n=== Summary Statistics ===\")\n",
        "print(f\"Euclidean Distance - Mean: {euclidean_flat.mean():.4f}, Std: {euclidean_flat.std():.4f}\")\n",
        "print(f\"Cosine Distance - Mean: {cosine_flat.mean():.4f}, Std: {cosine_flat.std():.4f}\")\n",
        "print(f\"\\nRelated Samples (Euclidean) - Mean: {related_counts_euclidean.mean():.2f}, Std: {related_counts_euclidean.std():.2f}\")\n",
        "print(f\"Related Samples (Cosine) - Mean: {related_counts_cosine.mean():.2f}, Std: {related_counts_cosine.std():.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analysis and Conclusions\n",
        "\n",
        "### Key Observations:\n",
        "\n",
        "1. **Sample Density**: Some samples have many close neighbors, others are isolated\n",
        "2. **Metric Agreement**: Euclidean and cosine similarity may identify different relationships\n",
        "3. **Dataset Structure**: The distribution of related samples reveals clustering patterns\n",
        "\n",
        "### Research Insights:\n",
        "\n",
        "- Understanding sample relationships helps identify potential generalization challenges\n",
        "- Dense regions may indicate redundant information\n",
        "- Isolated samples may be outliers or unique cases\n",
        "- Different similarity metrics capture different aspects of relationships"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}

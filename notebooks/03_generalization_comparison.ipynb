{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalization Comparison and Conclusions\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook synthesizes results from similarity analysis and strategic splitting experiments, providing comprehensive conclusions about dataset structure and its impact on model generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import optimized similarity-aware split function\n",
    "from similarity_split_optimized import similarity_aware_split_optimized\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load All Saved Results\n",
    "\n",
    "Load results from previous notebooks using pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "results_dir = os.path.join(os.path.dirname(os.getcwd()), 'results')\n",
    "\n",
    "# Load all results\n",
    "all_results = {}\n",
    "\n",
    "try:\n",
    "    with open(os.path.join(results_dir, '01_similarity_results.pkl'), 'rb') as f:\n",
    "        all_results['similarity'] = pickle.load(f)\n",
    "    print(\"✓ Loaded similarity analysis results\")\n",
    "except FileNotFoundError:\n",
    "    print(\"⚠ Similarity results not found. Run notebook 01 first.\")\n",
    "\n",
    "try:\n",
    "    with open(os.path.join(results_dir, '02_splitting_results.pkl'), 'rb') as f:\n",
    "        all_results['splitting'] = pickle.load(f)\n",
    "    print(\"✓ Loaded splitting strategy results\")\n",
    "except FileNotFoundError:\n",
    "    print(\"⚠ Splitting results not found. Run notebook 02 first.\")\n",
    "\n",
    "print(f\"\\nLoaded {len(all_results)} result files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprehensive Comparison Analysis\n",
    "\n",
    "Compare all splitting strategies using loaded results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data (same as previous notebooks)\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
    "columns = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status',\n",
    "           'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss',\n",
    "           'hours-per-week', 'native-country', 'income']\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(url, names=columns, na_values=' ?', skipinitialspace=True)\n",
    "    df = df.dropna()\n",
    "except Exception as e:\n",
    "    print(f\"Failed to load from primary URL: {e}\")\n",
    "    print(\"Trying alternative source...\")\n",
    "    try:\n",
    "        from sklearn.datasets import fetch_openml\n",
    "        adult = fetch_openml(name='adult', version=2, as_frame=True, parser='pandas')\n",
    "        df = adult.frame\n",
    "        df.columns = columns\n",
    "        df = df.dropna()\n",
    "        print(\"Successfully loaded UCI Adult Income dataset from OpenML\")\n",
    "    except Exception as e2:\n",
    "        raise RuntimeError(\n",
    "            f\"Failed to load dataset from both sources. \"\n",
    "            f\"Primary error: {e}, Secondary error: {e2}. \"\n",
    "            f\"Please ensure internet connection is available or download the dataset manually.\"\n",
    "        )\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(\"No synthetic data is used in this project.\")\n",
    "\n",
    "# Preprocess\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "df_encoded = df.copy()\n",
    "for col in categorical_cols:\n",
    "    if col != 'income':\n",
    "        le = LabelEncoder()\n",
    "        df_encoded[col] = le.fit_transform(df[col].astype(str))\n",
    "\n",
    "target_encoder = LabelEncoder()\n",
    "y = target_encoder.fit_transform(df['income'])\n",
    "feature_cols = [col for col in df_encoded.columns if col != 'income']\n",
    "X = df_encoded[feature_cols].values\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(f\"Dataset shape: {X_scaled.shape}\")\n",
    "print(f\"Target distribution: {np.bincount(y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare All Splitting Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarity-aware split (using optimized version from similarity_split_optimized.py)\n",
    "# Note: Using full dataset now since the optimized version is fast enough\n",
    "train_idx_sim, test_idx_sim = similarity_aware_split_optimized(X_scaled, y, test_size=0.2)\n",
    "X_train_sim, X_test_sim = X_scaled[train_idx_sim], X_scaled[test_idx_sim]\n",
    "y_train_sim, y_test_sim = y[train_idx_sim], y[test_idx_sim]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final comparison results\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "results_dir = os.path.join(os.path.dirname(os.getcwd()), 'results')\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "final_comparison = {\n",
    "    'splitting_comparison': results,\n",
    "    'similarity_analysis': all_results.get('similarity', {}),\n",
    "    'summary': {\n",
    "        'best_method': min(results.items(), key=lambda x: x[1]['gap'])[0] if results else None,\n",
    "        'worst_gap': max([r['gap'] for r in results.values()]) if results else None\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(os.path.join(results_dir, '03_final_comparison.pkl'), 'wb') as f:\n",
    "    pickle.dump(final_comparison, f)\n",
    "\n",
    "print(f\"\\nFinal comparison saved to: {os.path.join(results_dir, '03_final_comparison.pkl')}\")\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Findings and Conclusions\n",
    "\n",
    "### 1. Sample Similarity Reveals Dataset Structure\n",
    "- Dense regions indicate redundant information\n",
    "- Isolated samples may be outliers or unique cases\n",
    "- Understanding relationships helps identify potential issues\n",
    "\n",
    "### 2. Strategic Splitting Impacts Generalization\n",
    "- Similarity-aware splits can reveal harder generalization scenarios\n",
    "- Stratified splits maintain class balance\n",
    "- Random splits may underestimate generalization challenges\n",
    "\n",
    "### 3. Research Implications\n",
    "- Dataset structure matters for model evaluation\n",
    "- Similarity analysis informs data collection strategies\n",
    "- Strategic splitting provides more realistic performance estimates"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalization Comparison and Conclusions\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook synthesizes results from similarity analysis and strategic splitting experiments, providing comprehensive conclusions about dataset structure and its impact on model generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load All Saved Results\n",
    "\n",
    "Load results from previous notebooks using pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded similarity analysis results\n",
      "✓ Loaded splitting strategy results\n",
      "\n",
      "Loaded 2 result files.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "results_dir = os.path.join(os.path.dirname(os.getcwd()), 'results')\n",
    "\n",
    "# Load all results\n",
    "all_results = {}\n",
    "\n",
    "try:\n",
    "    with open(os.path.join(results_dir, '01_similarity_results.pkl'), 'rb') as f:\n",
    "        all_results['similarity'] = pickle.load(f)\n",
    "    print(\"✓ Loaded similarity analysis results\")\n",
    "except FileNotFoundError:\n",
    "    print(\"⚠ Similarity results not found. Run notebook 01 first.\")\n",
    "\n",
    "try:\n",
    "    with open(os.path.join(results_dir, '02_splitting_results.pkl'), 'rb') as f:\n",
    "        all_results['splitting'] = pickle.load(f)\n",
    "    print(\"✓ Loaded splitting strategy results\")\n",
    "except FileNotFoundError:\n",
    "    print(\"⚠ Splitting results not found. Run notebook 02 first.\")\n",
    "\n",
    "print(f\"\\nLoaded {len(all_results)} result files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprehensive Comparison and Analysis\n",
    "\n",
    "Analyze and visualize results from notebooks 01 and 02.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity-Aware:\n",
      "  Train Accuracy: 0.9995, Test Accuracy: 0.8782\n",
      "  Generalization Gap: 0.1212\n",
      "  Train/Test F1: 0.9989/0.7272\n",
      "\n",
      "Random Split:\n",
      "  Train Accuracy: 0.9996, Test Accuracy: 0.8612\n",
      "  Generalization Gap: 0.1384\n",
      "  Train/Test F1: 0.9991/0.6885\n",
      "\n",
      "Stratified Split:\n",
      "  Train Accuracy: 0.9995, Test Accuracy: 0.8572\n",
      "  Generalization Gap: 0.1423\n",
      "  Train/Test F1: 0.9989/0.6811\n"
     ]
    }
   ],
   "source": [
    "# Extract and organize results from notebook 02\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "results_dir = os.path.join(os.path.dirname(os.getcwd()), 'results')\n",
    "\n",
    "# Load splitting results from notebook 02\n",
    "try:\n",
    "    with open(os.path.join(results_dir, '02_splitting_results.pkl'), 'rb') as f:\n",
    "        results = pickle.load(f)\n",
    "    print(\"✓ Successfully loaded splitting results from notebook 02\")\n",
    "    print(f\"  Models: {list(results.keys())}\")\n",
    "    print(f\"  Splitting strategies: {list(results[list(results.keys())[0]].keys())}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"✗ Error: Could not find splitting results from notebook 02\")\n",
    "    print(\"  Please run notebook 02 first to generate results\")\n",
    "    results = {}\n",
    "\n",
    "# Load similarity analysis results from notebook 01\n",
    "try:\n",
    "    with open(os.path.join(results_dir, '01_similarity_results.pkl'), 'rb') as f:\n",
    "        similarity_results = pickle.load(f)\n",
    "    print(\"\\n✓ Successfully loaded similarity analysis results from notebook 01\")\n",
    "except FileNotFoundError:\n",
    "    print(\"\\n⚠ Similarity analysis results not found. Run notebook 01 for complete analysis.\")\n",
    "    similarity_results = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final comparison saved to: /workspaces/dataset-structure-similarity-analysis/results/03_final_comparison.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Similarity-Aware': {'train_accuracy': 0.9994625513455411,\n",
       "  'test_accuracy': 0.8782248157248157,\n",
       "  'train_f1': 0.9988814317673378,\n",
       "  'test_f1': 0.7272101823185414,\n",
       "  'gap': 0.12123773562072537,\n",
       "  'train_size': 26049,\n",
       "  'test_size': 6512},\n",
       " 'Random Split': {'train_accuracy': 0.9995777027027027,\n",
       "  'test_accuracy': 0.861200675571933,\n",
       "  'train_f1': 0.9991220368744512,\n",
       "  'test_f1': 0.6884906960716747,\n",
       "  'gap': 0.13837702713076971,\n",
       "  'train_size': 26048,\n",
       "  'test_size': 6513},\n",
       " 'Stratified Split': {'train_accuracy': 0.9994625307125307,\n",
       "  'test_accuracy': 0.8572086596038692,\n",
       "  'train_f1': 0.9988832163369495,\n",
       "  'test_f1': 0.6810699588477366,\n",
       "  'gap': 0.1422538711086615,\n",
       "  'train_size': 26048,\n",
       "  'test_size': 6513}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save comprehensive analysis summary\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "results_dir = os.path.join(os.path.dirname(os.getcwd()), 'results')\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "final_comparison = {\n",
    "    'splitting_comparison': results,\n",
    "    'similarity_analysis': similarity_results,\n",
    "    'summary': {\n",
    "        'models_tested': list(results.keys()) if results else [],\n",
    "        'splits_tested': list(results[list(results.keys())[0]].keys()) if results else [],\n",
    "    }\n",
    "}\n",
    "\n",
    "# Calculate best performing strategy for each model\n",
    "if results:\n",
    "    for model_name in results:\n",
    "        best_split = min(results[model_name].items(), key=lambda x: x[1]['gap']) if results[model_name] else None\n",
    "        final_comparison['summary'][f'{model_name}_best_split'] = best_split[0] if best_split else None\n",
    "        final_comparison['summary'][f'{model_name}_min_gap'] = best_split[1]['gap'] if best_split else None\n",
    "\n",
    "with open(os.path.join(results_dir, '03_final_comparison.pkl'), 'wb') as f:\n",
    "    pickle.dump(final_comparison, f)\n",
    "\n",
    "print(f\"\\nFinal comparison saved to: {os.path.join(results_dir, '03_final_comparison.pkl')}\")\n",
    "\n",
    "if results:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SUMMARY OF RESULTS FROM NOTEBOOK 02\")\n",
    "    print(\"=\"*80)\n",
    "    for model_name, splits_res in results.items():\n",
    "        print(f\"\\n{model_name}:\")\n",
    "        for split_name, metrics in splits_res.items():\n",
    "            print(f\"  {split_name:20s}: Gap={metrics['gap']:.4f}, Test Acc={metrics['test_accuracy']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Findings and Conclusions\n",
    "\n",
    "### 1. Sample Similarity Reveals Dataset Structure\n",
    "- Dense regions indicate redundant information\n",
    "- Isolated samples may be outliers or unique cases\n",
    "- Understanding relationships helps identify potential issues\n",
    "\n",
    "### 2. Strategic Splitting Impacts Generalization\n",
    "- Similarity-aware splits can reveal harder generalization scenarios\n",
    "- Stratified splits maintain class balance\n",
    "- Random splits may underestimate generalization challenges\n",
    "\n",
    "### 3. Research Implications\n",
    "- Dataset structure matters for model evaluation\n",
    "- Similarity analysis informs data collection strategies\n",
    "- Strategic splitting provides more realistic performance estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive Visualization and Analysis\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 11))\n",
    "\n",
    "splits_list = ['Random', 'Stratified', 'Similarity-Aware']\n",
    "models_list = list(results.keys())\n",
    "\n",
    "# Subplot 1: Test Accuracy Comparison Across Splits and Models\n",
    "ax1 = axes[0, 0]\n",
    "x = np.arange(len(splits_list))\n",
    "width = 0.35\n",
    "\n",
    "test_accs_lr = [results['Logistic Regression'][split]['test_accuracy'] for split in splits_list]\n",
    "test_accs_rf = [results['Random Forest'][split]['test_accuracy'] for split in splits_list]\n",
    "\n",
    "ax1.bar(x - width/2, test_accs_lr, width, label='Logistic Regression', alpha=0.8)\n",
    "ax1.bar(x + width/2, test_accs_rf, width, label='Random Forest', alpha=0.8)\n",
    "ax1.set_xlabel('Splitting Strategy', fontsize=11)\n",
    "ax1.set_ylabel('Test Accuracy', fontsize=11)\n",
    "ax1.set_title('Effect of Splitting on Test Accuracy', fontsize=12, fontweight='bold')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(splits_list, rotation=15)\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Subplot 2: Generalization Gap Comparison\n",
    "ax2 = axes[0, 1]\n",
    "gaps_lr = [results['Logistic Regression'][split]['gap'] for split in splits_list]\n",
    "gaps_rf = [results['Random Forest'][split]['gap'] for split in splits_list]\n",
    "\n",
    "x = np.arange(len(splits_list))\n",
    "ax2.bar(x - width/2, gaps_lr, width, label='Logistic Regression', alpha=0.8, edgecolor='black')\n",
    "ax2.bar(x + width/2, gaps_rf, width, label='Random Forest', alpha=0.8, edgecolor='black')\n",
    "ax2.set_xlabel('Splitting Strategy', fontsize=11)\n",
    "ax2.set_ylabel('Generalization Gap (Train - Test)', fontsize=11)\n",
    "ax2.set_title('Generalization Gap Comparison', fontsize=12, fontweight='bold')\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(splits_list, rotation=15)\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add note about lower gaps being better\n",
    "ax2.text(0.5, 0.95, '(Lower is better)', transform=ax2.transAxes, \n",
    "         ha='center', va='top', fontsize=9, style='italic', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.3))\n",
    "\n",
    "# Subplot 3: Train vs Test Accuracy by Model\n",
    "ax3 = axes[1, 0]\n",
    "models_x = np.arange(len(models_list))\n",
    "model_width = 0.25\n",
    "\n",
    "for i, split in enumerate(splits_list):\n",
    "    train_accs = [results[model][split]['train_accuracy'] for model in models_list]\n",
    "    test_accs = [results[model][split]['test_accuracy'] for model in models_list]\n",
    "    \n",
    "    offset = (i - 1) * model_width\n",
    "    ax3.bar(models_x + offset - 0.15, train_accs, model_width/2, alpha=0.7, label=f'{split} (Train)')\n",
    "    ax3.bar(models_x + offset + 0.15, test_accs, model_width/2, alpha=0.7, label=f'{split} (Test)')\n",
    "\n",
    "ax3.set_xlabel('Model', fontsize=11)\n",
    "ax3.set_ylabel('Accuracy', fontsize=11)\n",
    "ax3.set_title('Train vs Test Accuracy by Model', fontsize=12, fontweight='bold')\n",
    "ax3.set_xticks(models_x)\n",
    "ax3.set_xticklabels(models_list)\n",
    "ax3.legend(fontsize=8, loc='lower right')\n",
    "ax3.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Subplot 4: Impact of Similarity-Aware Split on Gap Reduction\n",
    "ax4 = axes[1, 1]\n",
    "\n",
    "# Calculate gap reduction compared to random split\n",
    "gap_reduction_lr = (gaps_lr[0] - np.array(gaps_lr)) / gaps_lr[0] * 100 if gaps_lr[0] != 0 else np.zeros(len(gaps_lr))\n",
    "gap_reduction_rf = (gaps_rf[0] - np.array(gaps_rf)) / gaps_rf[0] * 100 if gaps_rf[0] != 0 else np.zeros(len(gaps_rf))\n",
    "\n",
    "x = np.arange(len(splits_list))\n",
    "ax4.bar(x - width/2, gap_reduction_lr, width, label='Logistic Regression', alpha=0.8)\n",
    "ax4.bar(x + width/2, gap_reduction_rf, width, label='Random Forest', alpha=0.8)\n",
    "ax4.axhline(y=0, color='black', linestyle='-', linewidth=0.8, alpha=0.3)\n",
    "ax4.set_xlabel('Splitting Strategy', fontsize=11)\n",
    "ax4.set_ylabel('Gap Reduction (%)', fontsize=11)\n",
    "ax4.set_title('Gap Reduction vs Random Split', fontsize=12, fontweight='bold')\n",
    "ax4.set_xticks(x)\n",
    "ax4.set_xticklabels(splits_list, rotation=15)\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print detailed comparison\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DETAILED COMPARISON: LOGISTIC REGRESSION vs RANDOM FOREST\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for split_name in splits_list:\n",
    "    print(f\"\\n{split_name.upper()} SPLIT:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"{'Metric':<25} {'Logistic Regression':<25} {'Random Forest':<25} {'Difference':<15}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    lr_res = results['Logistic Regression'][split_name]\n",
    "    rf_res = results['Random Forest'][split_name]\n",
    "    \n",
    "    metrics = [\n",
    "        ('Train Accuracy', 'train_accuracy'),\n",
    "        ('Test Accuracy', 'test_accuracy'),\n",
    "        ('Train F1', 'train_f1'),\n",
    "        ('Test F1', 'test_f1'),\n",
    "        ('Generalization Gap', 'gap')\n",
    "    ]\n",
    "    \n",
    "    for metric_label, metric_key in metrics:\n",
    "        lr_val = lr_res[metric_key]\n",
    "        rf_val = rf_res[metric_key]\n",
    "        diff = rf_val - lr_val\n",
    "        print(f\"{metric_label:<25} {lr_val:<25.4f} {rf_val:<25.4f} {diff:+.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"KEY FINDINGS:\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\n1. Model Performance:\")\n",
    "print(f\"   - Logistic Regression typically shows smaller gaps on simple splits\")\n",
    "print(f\"   - Random Forest may capture more complex patterns\")\n",
    "\n",
    "print(\"\\n2. Effect of Similarity-Aware Splitting:\")\n",
    "for model_name in models_list:\n",
    "    random_gap = results[model_name]['Random']['gap']\n",
    "    sim_gap = results[model_name]['Similarity-Aware']['gap']\n",
    "    gap_change = ((sim_gap - random_gap) / random_gap) * 100 if random_gap != 0 else 0\n",
    "    print(f\"   - {model_name}: {gap_change:+.2f}% change in gap\")\n",
    "    if gap_change > 0:\n",
    "        print(f\"     (Similarity-aware split INCREASES gap - harder test set)\")\n",
    "    else:\n",
    "        print(f\"     (Similarity-aware split DECREASES gap - easier test set)\")\n",
    "\n",
    "print(\"\\n3. Best Splitting Strategy:\")\n",
    "for model_name in models_list:\n",
    "    best_split = min(results[model_name].items(), key=lambda x: x[1]['gap'])\n",
    "    print(f\"   - {model_name}: {best_split[0]} (gap: {best_split[1]['gap']:.4f})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
